# -*- coding: utf-8 -*-
"""3 - RegresionLineal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a90d2-4KbS5LDTZrY0YNahogQs0hdG5D

***Carga de las bibliotecas***
"""

import os
import math
import warnings
import numpy as np
import pandas as pd
import seaborn as sns
from scipy import stats
import plotly.express as px
from matplotlib import style
import statsmodels.api as sm
import matplotlib.pyplot as plt
from scipy.stats import pearsonr
from sklearn.metrics import r2_score
import statsmodels.formula.api as smf
from statsmodels.stats.anova import anova_lm
from sklearn.compose import ColumnTransformer
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import OneHotEncoder
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
warnings.filterwarnings('ignore')

"""***Carga del dataset***"""

data = pd.read_csv("/content/drive/MyDrive/ESCOM/8vo Semestre/Data Mining/Extraordinario/insurance.csv")

X = data.iloc[:, :-1]
y = data.iloc[:, -1]

"""***Visualización del dataset***"""

data.head()

data.tail()

data.describe()

"""***Comprobación de datos faltantes***"""

data.isnull().values.any()

"""***Visualización del mapa de calor***"""

sns.heatmap(data.corr(),annot= True)

"""El mapa de calor demuestra el coeficiente de correlación, que cuantifica la relación entre todas las variables. La edad y la prima del seguro parecen tener la mayor correlación entre todas las demás variables x.
IMC también tiene un ligero efecto sobre los cargos.
Todo lo que supere 0.5 significa que tienen una relación sólida (1 es una relación lineal perfecta)

***Visualización de la matriz de diagramas de dispersión***
"""

sns.pairplot(data)

"""El diagrama de pares o la matriz del diagrama de dispersión visualizan la relación entre las variables en una matriz.

***Visualización de la gráfica de dispersión 3D para ver la relación entre Edad, IMC y Prima del seguro***
"""

fig = px.scatter_3d(data, x='age', y='bmi', z='charges', color= 'sex')
fig.show()

"""A medida que aumenta la edad, las prima de seguro también aumentan. Esto verifica el coeficiente de correlación de 0.3 entre edad y cargos. IMC con cargos muestra la misma relación pero más débil.

***Construyendo modelo de regresión***
"""

ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1,4,5])], remainder='passthrough')
X = np.array(ct.fit_transform(X))

"""***Codificar las variables categóricas***"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

"""***Entrena, prueba dividida 80/20***"""

regressor = LinearRegression()
regressor.fit(X_train, y_train)

"""***Modelo de ajuste***"""

y_pred = regressor.predict(X_test)
math.sqrt(mean_squared_error(y_test, y_pred))

"""Usando el error cuadrático medio de la raíz, podemos determinar la precisión de este modelo (cuán preciso puede predecir este modelo). Según el resultado de la regresión, podemos ver que la raíz del error cuadrático medio es 5641,62. RMSE es la desviación estándar de la variación aleatoria (errores de predicción). Por lo tanto, podemos esperar que este modelo prediga los cargos dentro de una desviación estándar de 5641.62."""

r2_score(y_test, y_pred)
print(1 - (1-regressor.score(X, y))*(len(y)-1)/(len(y)-X.shape[1]-1))

"""Podemos ver que el R2 es 0,799. Tenemos una regla de oro que cuando R2 es mayor que 0.7, indica que es un buen modelo. R2 es un número de variación sistemática sobre la variación total. Esto significa que el 79,9% de las variaciones son sistemáticas. Si queremos saber cuál es el porcentaje de variación aleatoria, podemos dejar 100-79,9 = 25,31%. Por tanto, el 20,1% son variaciones aleatorias, que es un número pequeño. Sin embargo, para evaluar la Regresión multivariable, necesitamos saber que al sumar x variables, R2 siempre aumenta. Por lo tanto, R2 ajustado proporciona una comparación de "manzanas con manzanas" de los modelos, que es 0,7469. Según la regla de oro, este sigue siendo un modelo muy razonable.

***Gráfica de residuales***
"""

modelo  = sm.OLS(endog=y_train, exog=X_train,)
modelo  = modelo.fit()

#y_train = y_train.flatten()
prediccion_train = modelo.predict(exog = X_train)
residuos_train   = prediccion_train - y_train

plt.scatter(list(range(len(y_train))), residuos_train,edgecolors=(0, 0, 0), alpha = 0.4)
plt.axhline(y = 0, linestyle = '--', color = 'black', lw=2)
plt.title('Residuos del modelo', fontsize = 10, fontweight = "bold")
plt.xlabel('id')
plt.ylabel('Residuo')
plt.tick_params(labelsize = 7)

"""Los residuos no parecen distribuirse de forma aleatoria en torno a cero, sin mantener aproximadamente la misma variabilidad a lo largo del eje X. Este patrón apunta a una falta de homocedasticidad y de distribución normal.

***Valor predicho vs valor real***
"""

plt.scatter(y_train, prediccion_train, edgecolors=(0, 0, 0), alpha = 0.4)
plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', color = 'black', lw=2)
plt.title('Valor predicho vs valor real', fontsize = 10, fontweight = "bold")
plt.xlabel('Real')
plt.ylabel('Predicción')
plt.tick_params(labelsize = 7)

"""***Prueba de normalidad***

Normalidad de los residuos Shapiro-Wilk test
"""

shapiro_test = stats.shapiro(residuos_train)
shapiro_test

"""Normalidad de los residuos D'Agostino's K-squared test"""

k2, p_value = stats.normaltest(residuos_train)
print(f"Estadítico= {k2}, p-value = {p_value}")

"""Ambos test muestran claras evidencias para rechazar la hipótesis de que los datos se distribuyen de forma normal (p-value << 0.01).

***Prueba de significancia estadística (F-test)***
"""

print(modelo.fvalue, modelo.f_pvalue)

"""Cuando no se cumple la condición de normalidad, estos valores no son fiables. Una mejor aproximación es recurrir a un test de permutación. Para ello, se simula la hipótesis nula de "no asociación entre la variable respuesta y todos predictores", intercambiando aleatoriamente la variable respuesta entre las observaciones."""