# -*- coding: utf-8 -*-
"""4 - RegresionLogistica.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dtfOsboATmPKpuCgTkz0GiSn2epHvxnu

***Carga de las bibliotecas***
"""

import os
import numpy as np
import pandas as pd
import seaborn as sns
from collections import Counter
import matplotlib.pyplot as plt
#import scikitplot.metrics as splt
from imblearn.over_sampling import SMOTE
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

"""***Carga del dataset***"""

df = pd.read_csv('/content/drive/MyDrive/ESCOM/8vo Semestre/Data Mining/Extraordinario/Social_Network_Ads.csv')

"""***Análisis de los datos***"""

df.head()

df.info()

df.describe()

df.isnull().all()

"""***Distribución de los datos***

Diagramas de caja y bigote, e histogramas
"""

fig, axes = plt.subplots(2, 2, figsize=(15, 10))
sns.boxplot(ax=axes[0,0],x= df['Age'], palette = "Set1")
axes[0,0].set_title('Edad de las personas')
sns.histplot(ax=axes[0,1],x='Age',data=df,color="g")
axes[0,1].set_title('Distribución de las edades')

sns.boxplot(ax=axes[1,0],data = df['EstimatedSalary'])
axes[1,0].set_title('Salario estimado de las personas')
sns.histplot(ax=axes[1,1],x='EstimatedSalary',data=df,color="y")
axes[1,1].set_title('Distribución del salario estimado')
plt.show()

"""Diagramas de caja y bigote"""

fig, axes = plt.subplots(1, 2, figsize=(15,5))
sns.boxplot(ax=axes[0],x=df['Gender'], y=df['EstimatedSalary'], palette="PRGn")
axes[0].set_title('Salario esimado por genero')

sns.boxplot(ax=axes[1],x=df['Gender'], y=df['Age'], palette="pink")
axes[1].set_title('Edades por género')
plt.show()

"""Histogramas"""

fig ,axes = plt.subplots(1,2, figsize=(15,5))
sns.countplot(ax=axes[0],x='Purchased',data=df)
axes[0].set_title('Número de personas compradas')
sns.countplot(ax=axes[1],x='Purchased',hue='Gender',data=df,palette="magma")
axes[1].set_title('Número de personas compradas por género')
plt.show()

df.corr()

"""Mapa de calor"""

f,ax = plt.subplots(figsize=(6, 5))

sns.heatmap(df.corr(), annot=True, linewidths=0.5,linecolor="red", fmt= '.1f',cmap='viridis',ax=ax)
plt.show()

"""***Preparado los datos***"""

df.drop('User ID',axis = 1, inplace = True)
label = {'Male': 0 ,"Female" : 1}
df['Gender'].replace(label, inplace= True)

"""***Predicción***

Configuración de entradas y salidas
"""

X = df.drop('Purchased',axis = 1)     
y = df['Purchased']

"""Escaliento de los datos"""

scaler = StandardScaler()
d_scaled = scaler.fit_transform(X)
data_scaled1 = pd.DataFrame(d_scaled)
data_scaled1.head()

X_train,X_test,y_train,y_test = train_test_split(d_scaled,y,test_size=0.20,random_state=42)

model = LogisticRegression(C=0.1,max_iter = 500)
model.fit(X_train,y_train)

y_pred = model.predict(X_test)

# y = B + W*x1...
print(f'Coeficiente de peso : {model.coef_}')
print(f'Bias : {model.intercept_}')

"""***Resultados de la predicción***

Precisión
"""

print(f'Precisión de la prueba: {model.score(X_test,y_test)}')
print(f'Precisión del entrenamiento: {model.score(X_train,y_train)}')

"""Reporte de clasificación"""

print(classification_report(y_test, y_pred))

"""Matriz de confusión"""

df = pd.DataFrame(confusion_matrix(y_test, y_pred),
                  columns = ['Positivo predictivo', 'Negativo predictivo'], 
                  index=['Positivo verdadero', 'Negativo Verdadero'])
df
#plt.plot_confusion_matrix(y_test,y_pred,figsize=(7,7))
#plt.show()

"""Medidas de la predicción"""

print("Exactitud:", accuracy_score(y_test,y_pred))
print("Precisión:", precision_score(y_test, y_pred, ))
print("Llamada:", recall_score(y_test,y_pred))
print("F1 Puntaje:", f1_score(y_test,y_pred))

"""Área bajo la curva"""

model_roc_auc = roc_auc_score(y_test, model.predict(X_test))

fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])
plt.figure()
plt.plot(fpr, tpr, label='AUC (area = %0.2f)' % model_roc_auc)
plt.plot([0, 1], [0, 1], 'r--')
plt.xlim(([0.0, 1.0]))
plt.ylim(([0.0, 1.05]))
plt.xlabel('Taza de Falso Positivo')
plt.ylabel('Taza de Verdader Positivo')
plt.title('ROC')
plt.show()

"""***Finalmente, podemos utilizar el método SMOTE, que es un proceso de aumento de datos, para aumentar la tasa de aprendizaje.***"""

sm = SMOTE(random_state = 2)
X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())

clf = LogisticRegression()
model_res = clf.fit(X_train_res, y_train_res)

print(f'Prueba de exactitud {model_res.score(X_test,y_test)}')

"""***Comparación del tamaño del conjunto de entrenamiento para el modelo***"""

print(f'Originalmente: {X_train.shape}')
print(f'Aplicando el método SMOTE: {X_train_res.shape}')